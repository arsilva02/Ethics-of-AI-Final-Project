{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhNR3fKcti3X"
      },
      "source": [
        "Ethics of AI Final Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDA7N4Ojtn8z",
        "outputId": "84e9decb-52cd-4fa8-890a-962372be19eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8paBa5URti3b"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from datasets import load_dataset\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import  DecisionTreeClassifier ,plot_tree, export_text# Decision tree algorithm and plotting functions for the Decision tree\n",
        "from matplotlib import pyplot as plt # plotting/graphing\n",
        "import numpy as np\n",
        "from itertools import product\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZnysdhyVti3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['is_dater_male', 'dater_age', 'dated_age', 'age_difference',\n",
              "       'are_same_race', 'same_race_importance_for_dater',\n",
              "       'same_religion_importance_for_dater',\n",
              "       'attractiveness_importance_for_dated', 'sincerity_importance_for_dated',\n",
              "       'intelligence_importance_for_dated', 'humor_importance_for_dated',\n",
              "       'ambition_importance_for_dated',\n",
              "       'shared_interests_importance_for_dated',\n",
              "       'attractiveness_score_of_dater_from_dated',\n",
              "       'sincerity_score_of_dater_from_dated',\n",
              "       'intelligence_score_of_dater_from_dated',\n",
              "       'humor_score_of_dater_from_dated', 'ambition_score_of_dater_from_dated',\n",
              "       'shared_interests_score_of_dater_from_dated',\n",
              "       'attractiveness_importance_for_dater', 'sincerity_importance_for_dater',\n",
              "       'intelligence_importance_for_dater', 'humor_importance_for_dater',\n",
              "       'ambition_importance_for_dater',\n",
              "       'shared_interests_importance_for_dater',\n",
              "       'self_reported_attractiveness_of_dater',\n",
              "       'self_reported_sincerity_of_dater',\n",
              "       'self_reported_intelligence_of_dater', 'self_reported_humor_of_dater',\n",
              "       'self_reported_ambition_of_dater',\n",
              "       'reported_attractiveness_of_dated_from_dater',\n",
              "       'reported_sincerity_of_dated_from_dater',\n",
              "       'reported_intelligence_of_dated_from_dater',\n",
              "       'reported_humor_of_dated_from_dater',\n",
              "       'reported_ambition_of_dated_from_dater',\n",
              "       'reported_shared_interests_of_dated_from_dater',\n",
              "       'dater_interest_in_sports', 'dater_interest_in_tvsports',\n",
              "       'dater_interest_in_exercise', 'dater_interest_in_dining',\n",
              "       'dater_interest_in_museums', 'dater_interest_in_art',\n",
              "       'dater_interest_in_hiking', 'dater_interest_in_gaming',\n",
              "       'dater_interest_in_clubbing', 'dater_interest_in_reading',\n",
              "       'dater_interest_in_tv', 'dater_interest_in_theater',\n",
              "       'dater_interest_in_movies', 'dater_interest_in_concerts',\n",
              "       'dater_interest_in_music', 'dater_interest_in_shopping',\n",
              "       'dater_interest_in_yoga', 'interests_correlation',\n",
              "       'expected_satisfaction_of_dater',\n",
              "       'expected_number_of_likes_of_dater_from_20_people',\n",
              "       'expected_number_of_dates_for_dater', 'dater_liked_dated',\n",
              "       'probability_dated_wants_to_date', 'already_met_before',\n",
              "       'dater_race_'Asian/Pacific Islander/Asian-American'',\n",
              "       'dater_race_'Black/African American'',\n",
              "       'dater_race_'Latino/Hispanic American'', 'dater_race_caucasian',\n",
              "       'dater_race_other',\n",
              "       'dated_race_'Asian/Pacific Islander/Asian-American'',\n",
              "       'dated_race_'Black/African American'',\n",
              "       'dated_race_'Latino/Hispanic American'', 'dated_race_caucasian',\n",
              "       'dated_race_other'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fetch dataset and apply processing file\n",
        "dataset = load_dataset(\"mstz/speeddating\",trust_remote_code=True)[\"train\"]\n",
        "\n",
        "# convert to df\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "\n",
        "# split into x and y sets\n",
        "X = df.drop(columns=['is_match','dater_wants_to_date','dated_wants_to_date']) # is match is our target variable, which is determined from the last 2 so we need to drop all\n",
        "X = pd.get_dummies(X) #get dummies for X\n",
        "y = df.is_match\n",
        "\n",
        "X.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMTRaXwfuFrq",
        "outputId": "b7f30c7b-2ef8-42d7-9d39-247f5c1ee9d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1048"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8GMSgrOcti3g"
      },
      "outputs": [],
      "source": [
        "# split into training and tests, ALL RANDOM STATES SET TO 0\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = .33,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hv99_gSti3h",
        "outputId": "7997c848-32eb-4fe2-c921-6c2c20adab9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83.31332309553726"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Different models\n",
        "# Random Forest\n",
        "\n",
        "#Set estimators as 100, random state 0, samples of at least 2 in each leaf\n",
        "clf = RandomForestClassifier(n_estimators = 125, random_state=0, min_samples_leaf=2)\n",
        "clf.fit(x_train, y_train) # fit model\n",
        "\n",
        "# get the roc auc and pring\n",
        "cross_val_accuracy_roc_auc = (cross_val_score(clf, x_train, y_train, cv = 10, scoring = 'roc_auc').mean()*100)\n",
        "\n",
        "cross_val_accuracy_roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_moeV7rti3i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBC0qX2Sti3j"
      },
      "source": [
        "# 1 Pre Processing\n",
        "Our dataset has a variety of features. We will want to simplify our dataset to have a few key features:\n",
        "Age, age difference for the pairing (Sensitive)\n",
        "Race, same race for the pairing (Sensitive)\n",
        "expected_number_of_likes_of_dater_from_20_people (non sensitive)\n",
        "Already met before (non sensitive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s41K5MnOti3j",
        "outputId": "0b726c2a-b2a3-4f78-c36e-7f522fb3adbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matches where pairings are the same race:  437\n",
            "Matches where pairings are not the same race:  611\n"
          ]
        }
      ],
      "source": [
        "features = ['dater_age','dated_age','age_difference','dater_race','dated_race','are_same_race','expected_number_of_likes_of_dater_from_20_people','already_met_before']\n",
        "\n",
        "X = df[features].copy()\n",
        "y = df.is_match.copy()\n",
        "\n",
        "# We will want to see where the race is the same or not\n",
        "\n",
        "print('Matches where pairings are the same race: ',len(X[X['are_same_race']]))\n",
        "print('Matches where pairings are not the same race: ',len(X[-X['are_same_race']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT7UZGflti3l",
        "outputId": "a4abded6-e5a9-42bf-ff48-fb18a7fe57cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matches where pairings are the same race and match:  84\n",
            "Matches where pairings are not the same race and match:  102\n"
          ]
        }
      ],
      "source": [
        "print('Matches where pairings are the same race and match: ',len(X[X['are_same_race'] & y==1]))\n",
        "print('Matches where pairings are not the same race and match: ',len(X[-X['are_same_race'] & y==1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI_j4q9Kti3m"
      },
      "source": [
        "# Split data and Examine Match Rates by Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_elUoEfkti3m",
        "outputId": "aa8daff1-6f7a-4e45-95ce-fd7a21dc8339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% Same Race in train:  0.4092769440654843\n",
            "% Not Same Race in train:  0.5907230559345157\n",
            "%  Same Race in test:  0.43492063492063493\n",
            "% Not Same Race test:  0.5650793650793651\n",
            "Difference in Match Rate between Groups in Training Data:  0.029622786759045422\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state= 372)\n",
        "\n",
        "print('% Same Race in train: ', len(X_train[X_train['are_same_race']])/len(X_train))\n",
        "print('% Not Same Race in train: ', len(X_train[-X_train['are_same_race']])/len(X_train))\n",
        "\n",
        "print('%  Same Race in test: ', len(X_test[X_test['are_same_race']])/len(X_test))\n",
        "print('% Not Same Race test: ', len(X_test[-X_test['are_same_race']])/len(X_test))\n",
        "\n",
        "#make a df where the couple is a match\n",
        "train_is_match = X_train.join(y_train)\n",
        "train_is_match = train_is_match[y_train==1]\n",
        "\n",
        "print('Difference in Match Rate between Groups in Training Data: ',\n",
        "    ( (len(train_is_match[train_is_match['are_same_race']]) / len(X_train[X_train['are_same_race']]))\n",
        "     -\n",
        "    ( (len(train_is_match[-train_is_match['are_same_race']])) / len(X_train[-X_train['are_same_race']])))\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adn2JqRWt-48"
      },
      "source": [
        "Metrics by Race"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "94VKnckCgXzH"
      },
      "outputs": [],
      "source": [
        "results = x_test\n",
        "y_hat = clf.predict(x_test)\n",
        "results['predicted'] = y_hat\n",
        "results['actual'] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "62K68RAOhZPk",
        "outputId": "b8a5bba2-72a9-41c0-b07a-d2868484a060"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_dater_male</th>\n",
              "      <th>dater_age</th>\n",
              "      <th>dated_age</th>\n",
              "      <th>age_difference</th>\n",
              "      <th>are_same_race</th>\n",
              "      <th>same_race_importance_for_dater</th>\n",
              "      <th>same_religion_importance_for_dater</th>\n",
              "      <th>attractiveness_importance_for_dated</th>\n",
              "      <th>sincerity_importance_for_dated</th>\n",
              "      <th>intelligence_importance_for_dated</th>\n",
              "      <th>...</th>\n",
              "      <th>dater_race_'Latino/Hispanic American'</th>\n",
              "      <th>dater_race_caucasian</th>\n",
              "      <th>dater_race_other</th>\n",
              "      <th>dated_race_'Asian/Pacific Islander/Asian-American'</th>\n",
              "      <th>dated_race_'Black/African American'</th>\n",
              "      <th>dated_race_'Latino/Hispanic American'</th>\n",
              "      <th>dated_race_caucasian</th>\n",
              "      <th>dated_race_other</th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>False</td>\n",
              "      <td>21</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>True</td>\n",
              "      <td>24</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>True</td>\n",
              "      <td>27</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     is_dater_male  dater_age  dated_age  age_difference  are_same_race  \\\n",
              "413           True         25         26               1          False   \n",
              "311           True         25         27               2          False   \n",
              "142          False         21         30               9          False   \n",
              "330           True         24         26               2           True   \n",
              "875           True         27         35               8          False   \n",
              "\n",
              "     same_race_importance_for_dater  same_religion_importance_for_dater  \\\n",
              "413                             1.0                                 3.0   \n",
              "311                             9.0                                 6.0   \n",
              "142                             9.0                                 6.0   \n",
              "330                             1.0                                 1.0   \n",
              "875                             6.0                                 8.0   \n",
              "\n",
              "     attractiveness_importance_for_dated  sincerity_importance_for_dated  \\\n",
              "413                                 20.0                            25.0   \n",
              "311                                 10.0                            10.0   \n",
              "142                                 20.0                            20.0   \n",
              "330                                 20.0                            25.0   \n",
              "875                                 10.0                            32.0   \n",
              "\n",
              "     intelligence_importance_for_dated  ...  \\\n",
              "413                               20.0  ...   \n",
              "311                               30.0  ...   \n",
              "142                               25.0  ...   \n",
              "330                               20.0  ...   \n",
              "875                               20.0  ...   \n",
              "\n",
              "     dater_race_'Latino/Hispanic American'  dater_race_caucasian  \\\n",
              "413                                      0                     0   \n",
              "311                                      0                     0   \n",
              "142                                      0                     0   \n",
              "330                                      0                     1   \n",
              "875                                      0                     1   \n",
              "\n",
              "     dater_race_other  dated_race_'Asian/Pacific Islander/Asian-American'  \\\n",
              "413                 0                                                  0    \n",
              "311                 0                                                  0    \n",
              "142                 0                                                  0    \n",
              "330                 0                                                  0    \n",
              "875                 0                                                  0    \n",
              "\n",
              "     dated_race_'Black/African American'  \\\n",
              "413                                    0   \n",
              "311                                    0   \n",
              "142                                    0   \n",
              "330                                    0   \n",
              "875                                    0   \n",
              "\n",
              "     dated_race_'Latino/Hispanic American'  dated_race_caucasian  \\\n",
              "413                                      0                     1   \n",
              "311                                      0                     1   \n",
              "142                                      0                     1   \n",
              "330                                      0                     1   \n",
              "875                                      1                     0   \n",
              "\n",
              "     dated_race_other  predicted  actual  \n",
              "413                 0          0     NaN  \n",
              "311                 0          0     NaN  \n",
              "142                 0          0     NaN  \n",
              "330                 0          0     NaN  \n",
              "875                 0          0     NaN  \n",
              "\n",
              "[5 rows x 72 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dmOs3cLZYRJl",
        "outputId": "869e3c66-94c8-4dc1-95e4-5d64f24218fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>tpr</th>\n",
              "      <th>fpr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dater_race_'Asian/Pacific Islander/Asian-Ameri...</td>\n",
              "      <td>0.289474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dater_race_'Black/African American'</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dater_race_'Latino/Hispanic American'</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dater_race_caucasian</td>\n",
              "      <td>0.265700</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.077295</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.036364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dater_race_other</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dated_race_'Asian/Pacific Islander/Asian-Ameri...</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>dated_race_'Black/African American'</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>dated_race_'Latino/Hispanic American'</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dated_race_caucasian</td>\n",
              "      <td>0.270408</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.018868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dated_race_other</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               group  accuracy  precision  \\\n",
              "0  dater_race_'Asian/Pacific Islander/Asian-Ameri...  0.289474   0.000000   \n",
              "1                dater_race_'Black/African American'  0.250000   0.500000   \n",
              "2              dater_race_'Latino/Hispanic American'  0.222222   0.000000   \n",
              "3                               dater_race_caucasian  0.265700   0.400000   \n",
              "4                                   dater_race_other  0.142857   0.000000   \n",
              "5  dated_race_'Asian/Pacific Islander/Asian-Ameri...  0.240000   0.000000   \n",
              "6                dated_race_'Black/African American'  0.250000   0.666667   \n",
              "7              dated_race_'Latino/Hispanic American'  0.185185   0.000000   \n",
              "8                               dated_race_caucasian  0.270408   0.333333   \n",
              "9                                   dated_race_other  0.291667   0.000000   \n",
              "\n",
              "     recall  positive_rate       tpr       fpr  \n",
              "0  0.000000       0.026316  0.000000  0.000000  \n",
              "1  0.500000       0.250000  0.500000  0.000000  \n",
              "2  0.000000       0.037037  0.000000  0.000000  \n",
              "3  0.181818       0.077295  0.181818  0.036364  \n",
              "4  0.000000       0.071429  0.000000  0.000000  \n",
              "5  0.000000       0.066667  0.000000  0.052632  \n",
              "6  0.400000       0.083333  0.400000  0.000000  \n",
              "7  0.000000       0.074074  0.000000  0.000000  \n",
              "8  0.100000       0.061224  0.100000  0.018868  \n",
              "9  0.000000       0.083333  0.000000  0.000000  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dater_groups = [\"dater_race_'Asian/Pacific Islander/Asian-American'\",\"dater_race_'Black/African American'\",\"dater_race_'Latino/Hispanic American'\", 'dater_race_caucasian','dater_race_other']\n",
        "dated_groups = [\"dated_race_'Asian/Pacific Islander/Asian-American'\",\"dated_race_'Black/African American'\",\"dated_race_'Latino/Hispanic American'\", 'dated_race_caucasian','dated_race_other']\n",
        "\n",
        "def compute_metrics(info, group):\n",
        "  metric_df = info.loc[info[group] == 1]\n",
        "  pred_pos = sum(metric_df['predicted'])\n",
        "  act_pos = sum(metric_df['actual'])\n",
        "\n",
        "  positive_rate = pred_pos/len(metric_df)\n",
        "  accuracy = len(metric_df[metric_df['predicted'] == metric_df['actual']])/len(metric_df)\n",
        "  tp = len(metric_df[(metric_df['actual'] == 1) & (metric_df['predicted'] == 1)])\n",
        "  fp = len(metric_df[(metric_df['actual'] == 0) & (metric_df['predicted'] == 1)])\n",
        "  fn = len(metric_df[(metric_df['actual'] == 1) & (metric_df['predicted'] == 0)])\n",
        "  tn = len(metric_df[(metric_df['actual'] == 0) & (metric_df['predicted'] == 0)])\n",
        "  tpr = tp/(tp + fn + 1)\n",
        "  fpr = fp/(fp + tn)\n",
        "  precision = tp/(tp + fp+ 1)\n",
        "  recall = tp/(tp + fn + 1)\n",
        "\n",
        "  row = [group, accuracy, precision, recall, positive_rate, tpr, fpr]\n",
        "\n",
        "  return row\n",
        "\n",
        "column_names = ['group', 'accuracy', 'precision', 'recall', 'positive_rate', 'tpr', 'fpr']\n",
        "metrics_df = pd.DataFrame(columns=column_names)\n",
        "for group in dater_groups:\n",
        "  row = compute_metrics(results, group)\n",
        "  metrics_df.loc[len(metrics_df)] = row\n",
        "\n",
        "for group in dated_groups:\n",
        "  row = compute_metrics(results, group)\n",
        "  metrics_df.loc[len(metrics_df)] = row\n",
        "\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfdHW5iVqisl"
      },
      "source": [
        "## 2 - Inprocess Bias Mitigation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIt0kaNNjhKU",
        "outputId": "4f65de05-ae35-4eef-92ac-3a168062c8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'same': 82.29589371980677, 'diff': 81.3318054494525}\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "X = df.drop(columns=['is_match','dater_wants_to_date','dated_wants_to_date']) # is match is our target variable, which is determined from the last 2 so we need to drop all\n",
        "X = pd.get_dummies(X) #get dummies for X\n",
        "y = df.is_match\n",
        "\n",
        "# Same race data split into y and X\n",
        "X_same = df[df['are_same_race'] == 1]\n",
        "y_same = X_same.is_match\n",
        "X_same = X_same.drop(columns=['is_match','dater_wants_to_date','dated_wants_to_date'])\n",
        "X_same = pd.get_dummies(X_same) #get dummies for X\n",
        "\n",
        "# Different race data split into y and x\n",
        "X_diff = df[df['are_same_race'] == 0]\n",
        "y_diff = X_diff.is_match\n",
        "X_diff = X_diff.drop(columns=['is_match','dater_wants_to_date','dated_wants_to_date'])\n",
        "X_diff = pd.get_dummies(X_diff) #get dummies for X\n",
        "\n",
        "x_train_same, x_test_same, y_train_same, y_test_same = train_test_split(X_same, y_same, test_size = .33,random_state=0)\n",
        "x_train_diff, x_test_diff, y_train_diff, y_test_diff = train_test_split(X_diff, y_diff, test_size = .33,random_state=0)\n",
        "\n",
        "clf1 = RandomForestClassifier(n_estimators = 125, random_state=0, min_samples_leaf=2)\n",
        "clf1.fit(x_train_same, y_train_same) # fit model\n",
        "\n",
        "clf2 = RandomForestClassifier(n_estimators = 125, random_state=0, min_samples_leaf=2)\n",
        "clf2.fit(x_train_diff, y_train_diff) # fit model\n",
        "\n",
        "cross_val_dict = {}\n",
        "# get the roc auc and pring\n",
        "# Diff\n",
        "cross_val_accuracy_roc_auc = (cross_val_score(clf1, x_train_same, y_train_same, cv = 10, scoring = 'roc_auc').mean()*100)\n",
        "\n",
        "cross_val_dict['same'] = cross_val_accuracy_roc_auc\n",
        "\n",
        "# Diff\n",
        "cross_val_accuracy_roc_auc = (cross_val_score(clf1, x_train_diff, y_train_diff, cv = 10, scoring = 'roc_auc').mean()*100)\n",
        "\n",
        "cross_val_dict['diff'] = cross_val_accuracy_roc_auc\n",
        "\n",
        "print(cross_val_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IQl9wY3Cq_6c"
      },
      "outputs": [],
      "source": [
        "# Same results\n",
        "results_same = x_test_same\n",
        "y_hat = clf1.predict(x_test_same)\n",
        "results_same['predicted'] = y_hat\n",
        "results_same['actual'] = y_test_same\n",
        "\n",
        "# Diff results\n",
        "results_diff = x_test_diff\n",
        "y_hat = clf2.predict(x_test_diff)\n",
        "results_diff['predicted'] = y_hat\n",
        "results_diff['actual'] = y_test_diff\n",
        "\n",
        "results = pd.concat([results_same, results_diff])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "--2EA4cV4TFx",
        "outputId": "43a742f1-e3ed-4bf4-ff18-541853d1a7d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-16301390-473a-4f4b-b9cc-d6c308503501\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_dater_male</th>\n",
              "      <th>dater_age</th>\n",
              "      <th>dated_age</th>\n",
              "      <th>age_difference</th>\n",
              "      <th>are_same_race</th>\n",
              "      <th>same_race_importance_for_dater</th>\n",
              "      <th>same_religion_importance_for_dater</th>\n",
              "      <th>attractiveness_importance_for_dated</th>\n",
              "      <th>sincerity_importance_for_dated</th>\n",
              "      <th>intelligence_importance_for_dated</th>\n",
              "      <th>...</th>\n",
              "      <th>dater_race_'Latino/Hispanic American'</th>\n",
              "      <th>dater_race_caucasian</th>\n",
              "      <th>dater_race_other</th>\n",
              "      <th>dated_race_'Asian/Pacific Islander/Asian-American'</th>\n",
              "      <th>dated_race_'Black/African American'</th>\n",
              "      <th>dated_race_'Latino/Hispanic American'</th>\n",
              "      <th>dated_race_caucasian</th>\n",
              "      <th>dated_race_other</th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>False</td>\n",
              "      <td>34</td>\n",
              "      <td>24</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>False</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>False</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>True</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>False</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 72 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16301390-473a-4f4b-b9cc-d6c308503501')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16301390-473a-4f4b-b9cc-d6c308503501 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16301390-473a-4f4b-b9cc-d6c308503501');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4853660-ac09-429c-a878-a830cf7234d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4853660-ac09-429c-a878-a830cf7234d4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4853660-ac09-429c-a878-a830cf7234d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     is_dater_male  dater_age  dated_age  age_difference  are_same_race  \\\n",
              "601          False         34         24              10           True   \n",
              "694          False         30         26               4           True   \n",
              "764          False         29         26               3           True   \n",
              "453           True         28         23               5           True   \n",
              "149          False         27         30               3           True   \n",
              "\n",
              "     same_race_importance_for_dater  same_religion_importance_for_dater  \\\n",
              "601                             5.0                                 7.0   \n",
              "694                             3.0                                 5.0   \n",
              "764                             1.0                                 2.0   \n",
              "453                             2.0                                 2.0   \n",
              "149                             2.0                                 3.0   \n",
              "\n",
              "     attractiveness_importance_for_dated  sincerity_importance_for_dated  \\\n",
              "601                                 10.0                            20.0   \n",
              "694                                 18.0                            18.0   \n",
              "764                                 18.0                            18.0   \n",
              "453                                 10.0                            20.0   \n",
              "149                                 20.0                            20.0   \n",
              "\n",
              "     intelligence_importance_for_dated  ...  \\\n",
              "601                               35.0  ...   \n",
              "694                               18.0  ...   \n",
              "764                               18.0  ...   \n",
              "453                               20.0  ...   \n",
              "149                               25.0  ...   \n",
              "\n",
              "     dater_race_'Latino/Hispanic American'  dater_race_caucasian  \\\n",
              "601                                  False                  True   \n",
              "694                                  False                  True   \n",
              "764                                  False                  True   \n",
              "453                                  False                  True   \n",
              "149                                  False                  True   \n",
              "\n",
              "     dater_race_other  dated_race_'Asian/Pacific Islander/Asian-American'  \\\n",
              "601             False                                              False    \n",
              "694             False                                              False    \n",
              "764             False                                              False    \n",
              "453             False                                              False    \n",
              "149             False                                              False    \n",
              "\n",
              "     dated_race_'Black/African American'  \\\n",
              "601                                False   \n",
              "694                                False   \n",
              "764                                False   \n",
              "453                                False   \n",
              "149                                False   \n",
              "\n",
              "     dated_race_'Latino/Hispanic American'  dated_race_caucasian  \\\n",
              "601                                  False                  True   \n",
              "694                                  False                  True   \n",
              "764                                  False                  True   \n",
              "453                                  False                  True   \n",
              "149                                  False                  True   \n",
              "\n",
              "     dated_race_other  predicted  actual  \n",
              "601             False          0       0  \n",
              "694             False          0       0  \n",
              "764             False          0       0  \n",
              "453             False          0       0  \n",
              "149             False          0       0  \n",
              "\n",
              "[5 rows x 72 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KioeNeWjvpvf"
      },
      "outputs": [],
      "source": [
        "dater_groups = [\"dater_race_'Asian/Pacific Islander/Asian-American'\",\"dater_race_'Black/African American'\",\"dater_race_'Latino/Hispanic American'\", 'dater_race_caucasian','dater_race_other']\n",
        "dated_groups = [\"dated_race_'Asian/Pacific Islander/Asian-American'\",\"dated_race_'Black/African American'\",\"dated_race_'Latino/Hispanic American'\", 'dated_race_caucasian','dated_race_other']\n",
        "\n",
        "def safe_divide(n, d):\n",
        "  try:\n",
        "    return n/d\n",
        "  except ZeroDivisionError:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def compute_metrics(info, group):\n",
        "  metric_df = info.loc[info[group] == 1]\n",
        "  pred_pos = sum(metric_df['predicted'])\n",
        "  act_pos = sum(metric_df['actual'])\n",
        "\n",
        "  positive_rate = pred_pos/len(metric_df)\n",
        "  accuracy = len(metric_df[metric_df['predicted'] == metric_df['actual']])/len(metric_df)\n",
        "  tp = len(metric_df[(metric_df['actual'] == 1) & (metric_df['predicted'] == 1)])\n",
        "  fp = len(metric_df[(metric_df['actual'] == 0) & (metric_df['predicted'] == 1)])\n",
        "  fn = len(metric_df[(metric_df['actual'] == 1) & (metric_df['predicted'] == 0)])\n",
        "  tn = len(metric_df[(metric_df['actual'] == 0) & (metric_df['predicted'] == 0)])\n",
        "  tpr = safe_divide(tp, (tp + fn))\n",
        "  fpr = safe_divide(fp, (fp + tn))\n",
        "  precision = safe_divide(tp, (tp + fp))\n",
        "  recall = safe_divide(tp, (tp + fn))\n",
        "\n",
        "  row = [group, accuracy, precision, recall, positive_rate, tpr, fpr]\n",
        "\n",
        "  return row\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xj7SjXLT2YVa",
        "outputId": "4de55748-a5f0-4f93-b961-7fa58e66cbe8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>tpr</th>\n",
              "      <th>fpr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dater_race_'Asian/Pacific Islander/Asian-Ameri...</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dater_race_'Black/African American'</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dater_race_'Latino/Hispanic American'</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dater_race_caucasian</td>\n",
              "      <td>0.847291</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>0.039409</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>0.011905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dater_race_other</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dated_race_'Asian/Pacific Islander/Asian-Ameri...</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>dated_race_'Black/African American'</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>dated_race_'Latino/Hispanic American'</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dated_race_caucasian</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.005525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dated_race_other</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               group  accuracy  precision  \\\n",
              "0  dater_race_'Asian/Pacific Islander/Asian-Ameri...  0.897436   0.500000   \n",
              "1                dater_race_'Black/African American'  0.888889   1.000000   \n",
              "2              dater_race_'Latino/Hispanic American'  0.870968        NaN   \n",
              "3                               dater_race_caucasian  0.847291   0.750000   \n",
              "4                                   dater_race_other  0.769231   1.000000   \n",
              "5  dated_race_'Asian/Pacific Islander/Asian-Ameri...  0.876712        NaN   \n",
              "6                dated_race_'Black/African American'  0.833333   1.000000   \n",
              "7              dated_race_'Latino/Hispanic American'  0.826087   0.500000   \n",
              "8                               dated_race_caucasian  0.857143   0.857143   \n",
              "9                                   dated_race_other  0.812500   0.750000   \n",
              "\n",
              "     recall  positive_rate       tpr       fpr  \n",
              "0  0.125000       0.025641  0.125000  0.014286  \n",
              "1  0.666667       0.222222  0.666667  0.000000  \n",
              "2  0.000000       0.000000  0.000000  0.000000  \n",
              "3  0.171429       0.039409  0.171429  0.011905  \n",
              "4  0.400000       0.153846  0.400000  0.000000  \n",
              "5  0.000000       0.000000  0.000000  0.000000  \n",
              "6  0.500000       0.166667  0.500000  0.000000  \n",
              "7  0.250000       0.086957  0.250000  0.052632  \n",
              "8  0.166667       0.032258  0.166667  0.005525  \n",
              "9  0.600000       0.250000  0.600000  0.090909  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_names = ['group', 'accuracy', 'precision', 'recall', 'positive_rate', 'tpr', 'fpr']\n",
        "metrics_df2 = pd.DataFrame(columns=column_names)\n",
        "for group in dater_groups:\n",
        "  row = compute_metrics(results, group)\n",
        "  metrics_df2.loc[len(metrics_df2)] = row\n",
        "\n",
        "for group in dated_groups:\n",
        "  row = compute_metrics(results, group)\n",
        "  metrics_df2.loc[len(metrics_df2)] = row\n",
        "\n",
        "metrics_df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "d3vQqRhU7hz9",
        "outputId": "a1d96818-a65e-4759-e78b-435826c06a3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>tpr</th>\n",
              "      <th>fpr</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dater_race_'Asian/Pacific Islander/Asian-American'</th>\n",
              "      <td>210.023310</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>-2.564103</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dater_race_'Black/African American'</th>\n",
              "      <td>255.555556</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>-11.111111</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dater_race_'Latino/Hispanic American'</th>\n",
              "      <td>291.935484</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dater_race_caucasian</th>\n",
              "      <td>218.889386</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>-5.714286</td>\n",
              "      <td>-49.014778</td>\n",
              "      <td>-5.714286</td>\n",
              "      <td>-67.261905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dater_race_other</th>\n",
              "      <td>438.461538</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>115.384615</td>\n",
              "      <td>inf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dated_race_'Asian/Pacific Islander/Asian-American'</th>\n",
              "      <td>265.296804</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dated_race_'Black/African American'</th>\n",
              "      <td>233.333333</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dated_race_'Latino/Hispanic American'</th>\n",
              "      <td>346.086957</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>17.391304</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dated_race_caucasian</th>\n",
              "      <td>216.981132</td>\n",
              "      <td>157.142857</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>-47.311828</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>-70.718232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dated_race_other</th>\n",
              "      <td>178.571429</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>inf</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      accuracy   precision  \\\n",
              "group                                                                        \n",
              "dater_race_'Asian/Pacific Islander/Asian-American'  210.023310         inf   \n",
              "dater_race_'Black/African American'                 255.555556  100.000000   \n",
              "dater_race_'Latino/Hispanic American'               291.935484         NaN   \n",
              "dater_race_caucasian                                218.889386   87.500000   \n",
              "dater_race_other                                    438.461538         inf   \n",
              "dated_race_'Asian/Pacific Islander/Asian-American'  265.296804         NaN   \n",
              "dated_race_'Black/African American'                 233.333333   50.000000   \n",
              "dated_race_'Latino/Hispanic American'               346.086957         inf   \n",
              "dated_race_caucasian                                216.981132  157.142857   \n",
              "dated_race_other                                    178.571429         inf   \n",
              "\n",
              "                                                       recall  positive_rate  \\\n",
              "group                                                                          \n",
              "dater_race_'Asian/Pacific Islander/Asian-American'        inf      -2.564103   \n",
              "dater_race_'Black/African American'                 33.333333     -11.111111   \n",
              "dater_race_'Latino/Hispanic American'                     NaN    -100.000000   \n",
              "dater_race_caucasian                                -5.714286     -49.014778   \n",
              "dater_race_other                                          inf     115.384615   \n",
              "dated_race_'Asian/Pacific Islander/Asian-American'        NaN    -100.000000   \n",
              "dated_race_'Black/African American'                 25.000000     100.000000   \n",
              "dated_race_'Latino/Hispanic American'                     inf      17.391304   \n",
              "dated_race_caucasian                                66.666667     -47.311828   \n",
              "dated_race_other                                          inf     200.000000   \n",
              "\n",
              "                                                          tpr         fpr  \n",
              "group                                                                      \n",
              "dater_race_'Asian/Pacific Islander/Asian-American'        inf         inf  \n",
              "dater_race_'Black/African American'                 33.333333         NaN  \n",
              "dater_race_'Latino/Hispanic American'                     NaN         NaN  \n",
              "dater_race_caucasian                                -5.714286  -67.261905  \n",
              "dater_race_other                                          inf         NaN  \n",
              "dated_race_'Asian/Pacific Islander/Asian-American'        NaN -100.000000  \n",
              "dated_race_'Black/African American'                 25.000000         NaN  \n",
              "dated_race_'Latino/Hispanic American'                     inf         inf  \n",
              "dated_race_caucasian                                66.666667  -70.718232  \n",
              "dated_race_other                                          inf         inf  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_df.set_index(metrics_df.columns[0], inplace=True)\n",
        "metrics_df2.set_index(metrics_df2.columns[0], inplace=True)\n",
        "\n",
        "perc_change_df = percentage_change = safe_divide((metrics_df2 - metrics_df), metrics_df) * 100\n",
        "perc_change_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5WxcDfgmgX"
      },
      "source": [
        "## 3 - Post-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5AEmmdpTgp7t"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dated_race\n- dater_race\nFeature names seen at fit time, yet now missing:\n- ambition_importance_for_dated\n- ambition_importance_for_dater\n- ambition_score_of_dater_from_dated\n- attractiveness_importance_for_dated\n- attractiveness_importance_for_dater\n- ...\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m threshold_values \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m90\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m y_hat_probs \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\arian\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    945\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    950\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
            "File \u001b[1;32mc:\\Users\\arian\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\arian\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\arian\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
            "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- dated_race\n- dater_race\nFeature names seen at fit time, yet now missing:\n- ambition_importance_for_dated\n- ambition_importance_for_dater\n- ambition_score_of_dater_from_dated\n- attractiveness_importance_for_dated\n- attractiveness_importance_for_dater\n- ...\n"
          ]
        }
      ],
      "source": [
        "threshold_values = [i/100 for i in range(50, 90)]\n",
        "y_hat_probs = clf.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_group_thresholds(y_true, y_proba, groups, threshold_values):\n",
        "\n",
        "  unique_groups = np.unique(groups)\n",
        "  all_combinations = list(product(threshold_values, repeat=len(unique_groups)))\n",
        "  results = []\n",
        "\n",
        "  for combination in all_combinations:\n",
        "    group_thresholds = {group: threshold for group, threshold in zip(unique_groups, combination)}\n",
        "  \n",
        "    y_pred = np.zeros(y_true.shape)\n",
        "    for group, threshold in group_thresholds.items():\n",
        "      group_mask = (groups == group)\n",
        "      y_pred[group_mask] = (y_proba[group_mask] > threshold)\n",
        "\n",
        "    fprs = {}\n",
        "    for group in unique_groups:\n",
        "      group_mask = (groups == group)\n",
        "      group_true = y_true[group_mask]\n",
        "      group_pred = y_pred[group_mask]\n",
        "      FP = np.sum((group_pred == 1) & (group_true == 0))\n",
        "      TN = np.sum((group_pred == 0) & (group_true == 0))\n",
        "      fprs[group] = FP / (FP + TN)\n",
        "\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    fpr_diff = fprs[unique_groups[0]] - fprs[unique_groups[1]] \n",
        "    row = [combination[0], combination[1], overall_accuracy, fpr_diff]\n",
        "    results.append(row)\n",
        "    \n",
        "    \n",
        "  columns = ['Threshold 0', 'Threshold 1', 'Model Accuracy', 'FPR Difference']\n",
        "  results_df = pd.DataFrame(results, columns=columns)\n",
        "  \n",
        "  return results_df\n",
        "results = evaluate_group_thresholds(y_true = y_test, \n",
        "                                    y_proba = y_hat_probs, \n",
        "                                    groups = X_test['groups'], \n",
        "                                    threshold_values = threshold_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr_threshold_subset = results[abs(results['FPR Difference']) < 0.01]\n",
        "max_accuracy_index = fpr_threshold_subset['Model Accuracy'].idxmax()\n",
        "max_accuracy_row = fpr_threshold_subset.loc[max_accuracy_index]\n",
        "max_accuracy_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_group_level_labels(y_proba, groups, max_accuracy_row):\n",
        "    y_pred = np.zeros(y_proba.shape)\n",
        "    for group in groups.unique():\n",
        "        group_mask = (groups == group)\n",
        "\n",
        "        threshold = max_accuracy_row['Threshold ' + str(group)]\n",
        "        \n",
        "        y_pred[group_mask] = (y_proba[group_mask] > threshold)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "y_hat_thresholds = generate_group_level_labels(y_proba=y_hat_probs,\n",
        "                                               groups=X_test['are_same_race'],\n",
        "                                               max_accuracy_row=max_accuracy_row)\n",
        "\n",
        "\n",
        "    \n",
        "y_hat_thresholds = generate_group_level_labels(y_proba = y_hat_probs,\n",
        "                                               groups = X_test['are_same_race'],\n",
        "                                               max_accuracy_row = max_accuracy_row)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_df = compute_metrics(y_hat = y_hat_thresholds,\n",
        "                             y_test = y_test,\n",
        "                             X_test = X_test)\n",
        "\n",
        "print(metrics_df.pivot(index='Metric', columns='Group', values='Value'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
